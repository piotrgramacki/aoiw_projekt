{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.settings import UC_MERCED_DATA_DIRECTORY, RESULTS_DIRECTORY\r\n",
    "from src.data.ucmerced_dataset import TripletDataModule\r\n",
    "from src.experiments import create_path_if_not_exists, run_bovw_experiments\r\n",
    "import os\r\n",
    "\r\n",
    "image_size = 256\r\n",
    "dm = TripletDataModule(UC_MERCED_DATA_DIRECTORY, image_size, 0.8, 100, augment=False, normalize=False, permute=True)\r\n",
    "dm.setup(None)\r\n",
    "train_dataset = dm.train_dataset\r\n",
    "test_dataset = dm.val_dataset\r\n",
    "\r\n",
    "output_sizes = [25, 50, 100, 150]\r\n",
    "samples = [10000]\r\n",
    "bovw_path = os.path.join(RESULTS_DIRECTORY, \"bovw\")\r\n",
    "create_path_if_not_exists(bovw_path)\r\n",
    "dataset_path = os.path.join(bovw_path, \"uc_merced\")\r\n",
    "create_path_if_not_exists(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, values_per_class, cluster_numbers, sample_numbers = run_bovw_experiments(train_dataset, test_dataset, output_sizes, samples, \"UC Merced\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "values_per_class = [list(list(zip(*single_experiment))[1]) for single_experiment in values_per_class]\r\n",
    "np.array(values_per_class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "class_names = dm.val_dataset.class_names\r\n",
    "df = pd.DataFrame.from_dict({\"clusters\": cluster_numbers, \"samples\": sample_numbers, \"anmrr\": values})\r\n",
    "values_per_class_without_labels = [list(list(zip(*single_experiment))[1]) for single_experiment in values_per_class]\r\n",
    "full_df = pd.concat([df, pd.DataFrame(np.array(values_per_class_without_labels), columns=class_names)], axis=1)\r\n",
    "results_long_form = full_df.melt(id_vars=['clusters', 'samples', 'anmrr'], var_name='class', value_name='anmrr_per_class')\r\n",
    "results_long_form['experiment_name'] = results_long_form.apply(lambda row: str(row['clusters']) + \"_\" + str(row['samples']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(values_per_class2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = pd.concat([df, pd.DataFrame(np.array(values_per_class2), columns=class_names)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\r\n",
    "\r\n",
    "ble = xd.melt(id_vars=['clusters', 'samples', 'anmrr'], var_name='class', value_name='anmrr_per_class')\r\n",
    "ble['experiment_name'] = ble.apply(lambda row: str(row['clusters']) + \"_\" + str(row['samples']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(ble, x='class', y='anmrr_per_class', color=['clusters', 'samples'])\r\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "df = pd.read_pickle(\"..\\\\results\\\\bovw\\\\pattern_net\\\\results_PatternNet.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import plotly.express as px\r\n",
    "\r\n",
    "def plot_bovw_results(df_path: str):\r\n",
    "    df = pd.read_pickle(df_path)\r\n",
    "    df['experiment_name'] = df.apply(lambda row: str(row['clusters']) + \"_\" + str(row['samples']), axis=1)\r\n",
    "    df['anmrr_text'] = df.apply(lambda row: f\"{row['anmrr']:.3f}\", axis=1)\r\n",
    "\r\n",
    "    fig = px.bar(df, x='experiment_name', y='anmrr', color='undersampling', barmode='group', text='anmrr_text', labels={'experiment_name':'Experiment name', 'anmrr': 'ANMRR'})\r\n",
    "    fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_triplet_results(df_path: str):\r\n",
    "    df = pd.read_pickle(df_path)\r\n",
    "    results_long_form = df.melt(id_vars=['model', 'output_size', 'anmrr'], var_name='class', value_name='anmrr_per_class')\r\n",
    "    results_long_form['experiment_name'] = results_long_form.apply(lambda row: str(row['model']) + \"_\" + str(row['output_size']), axis=1)\r\n",
    "    print(results_long_form.head())\r\n",
    "    fig = px.bar(results_long_form, x='class', y='anmrr_per_class', color='experiment_name', barmode='group')\r\n",
    "    fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bovw_results(\"..\\\\results\\\\bovw\\\\pattern_net\\\\results_PatternNet.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_triplet_results(\"..\\\\results\\\\triplet\\\\uc_merced\\\\results_uc_merced.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bovw_results(\"..\\\\results\\\\bovw\\\\uc_merced_eq\\\\results_UC Merced Equalized.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bovw_results(\"..\\\\results\\\\bovw\\\\uc_merced\\\\results_UC Merced.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "df = pd.read_pickle(\"..\\\\results\\\\bovw\\\\pattern_net\\\\results_PatternNet.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clusters</th>\n      <th>samples</th>\n      <th>anmrr</th>\n      <th>undersampling</th>\n      <th>airplane</th>\n      <th>baseball_field</th>\n      <th>basketball_court</th>\n      <th>beach</th>\n      <th>bridge</th>\n      <th>cemetery</th>\n      <th>...</th>\n      <th>runway</th>\n      <th>runway_marking</th>\n      <th>shipping_yard</th>\n      <th>solar_panel</th>\n      <th>sparse_residential</th>\n      <th>storage_tank</th>\n      <th>swimming_pool</th>\n      <th>tennis_court</th>\n      <th>transformer_station</th>\n      <th>wastewater_treatment_plant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>5000</td>\n      <td>0.644832</td>\n      <td>True</td>\n      <td>0.791870</td>\n      <td>0.713724</td>\n      <td>0.817263</td>\n      <td>0.763676</td>\n      <td>0.898288</td>\n      <td>0.701439</td>\n      <td>...</td>\n      <td>0.888172</td>\n      <td>0.638481</td>\n      <td>0.706393</td>\n      <td>0.804582</td>\n      <td>0.680476</td>\n      <td>0.874000</td>\n      <td>0.647231</td>\n      <td>0.759410</td>\n      <td>0.629754</td>\n      <td>0.585639</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25</td>\n      <td>5000</td>\n      <td>0.646735</td>\n      <td>False</td>\n      <td>0.804999</td>\n      <td>0.699511</td>\n      <td>0.813308</td>\n      <td>0.781790</td>\n      <td>0.900840</td>\n      <td>0.709100</td>\n      <td>...</td>\n      <td>0.894411</td>\n      <td>0.637496</td>\n      <td>0.720900</td>\n      <td>0.800527</td>\n      <td>0.684579</td>\n      <td>0.873482</td>\n      <td>0.646908</td>\n      <td>0.764294</td>\n      <td>0.625601</td>\n      <td>0.584447</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25</td>\n      <td>10000</td>\n      <td>0.647640</td>\n      <td>True</td>\n      <td>0.807403</td>\n      <td>0.705663</td>\n      <td>0.816795</td>\n      <td>0.772648</td>\n      <td>0.897284</td>\n      <td>0.692943</td>\n      <td>...</td>\n      <td>0.891773</td>\n      <td>0.634719</td>\n      <td>0.716084</td>\n      <td>0.800317</td>\n      <td>0.686905</td>\n      <td>0.873231</td>\n      <td>0.635611</td>\n      <td>0.755900</td>\n      <td>0.616440</td>\n      <td>0.561037</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25</td>\n      <td>10000</td>\n      <td>0.647344</td>\n      <td>False</td>\n      <td>0.803732</td>\n      <td>0.706661</td>\n      <td>0.819695</td>\n      <td>0.786367</td>\n      <td>0.896956</td>\n      <td>0.700060</td>\n      <td>...</td>\n      <td>0.887271</td>\n      <td>0.574070</td>\n      <td>0.725146</td>\n      <td>0.797050</td>\n      <td>0.695257</td>\n      <td>0.874446</td>\n      <td>0.647427</td>\n      <td>0.770502</td>\n      <td>0.639442</td>\n      <td>0.586556</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25</td>\n      <td>20000</td>\n      <td>0.646314</td>\n      <td>True</td>\n      <td>0.799734</td>\n      <td>0.707380</td>\n      <td>0.815179</td>\n      <td>0.774624</td>\n      <td>0.897977</td>\n      <td>0.699360</td>\n      <td>...</td>\n      <td>0.885199</td>\n      <td>0.625499</td>\n      <td>0.711819</td>\n      <td>0.810539</td>\n      <td>0.681311</td>\n      <td>0.876578</td>\n      <td>0.639546</td>\n      <td>0.752009</td>\n      <td>0.618774</td>\n      <td>0.565003</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>25</td>\n      <td>20000</td>\n      <td>0.645569</td>\n      <td>False</td>\n      <td>0.805595</td>\n      <td>0.700851</td>\n      <td>0.817944</td>\n      <td>0.784607</td>\n      <td>0.900008</td>\n      <td>0.708243</td>\n      <td>...</td>\n      <td>0.890112</td>\n      <td>0.596740</td>\n      <td>0.717653</td>\n      <td>0.807429</td>\n      <td>0.692721</td>\n      <td>0.868053</td>\n      <td>0.646169</td>\n      <td>0.765396</td>\n      <td>0.630462</td>\n      <td>0.583237</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>25</td>\n      <td>50000</td>\n      <td>0.648583</td>\n      <td>True</td>\n      <td>0.804629</td>\n      <td>0.700860</td>\n      <td>0.815215</td>\n      <td>0.786506</td>\n      <td>0.901078</td>\n      <td>0.702336</td>\n      <td>...</td>\n      <td>0.891594</td>\n      <td>0.636579</td>\n      <td>0.709716</td>\n      <td>0.803821</td>\n      <td>0.682903</td>\n      <td>0.875803</td>\n      <td>0.640217</td>\n      <td>0.763071</td>\n      <td>0.617895</td>\n      <td>0.578936</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>25</td>\n      <td>50000</td>\n      <td>0.651079</td>\n      <td>False</td>\n      <td>0.810678</td>\n      <td>0.701116</td>\n      <td>0.814006</td>\n      <td>0.780173</td>\n      <td>0.899064</td>\n      <td>0.709085</td>\n      <td>...</td>\n      <td>0.894761</td>\n      <td>0.637647</td>\n      <td>0.722124</td>\n      <td>0.803145</td>\n      <td>0.692819</td>\n      <td>0.874163</td>\n      <td>0.657273</td>\n      <td>0.759544</td>\n      <td>0.642925</td>\n      <td>0.571599</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>50</td>\n      <td>5000</td>\n      <td>0.637655</td>\n      <td>True</td>\n      <td>0.801461</td>\n      <td>0.711654</td>\n      <td>0.799366</td>\n      <td>0.721935</td>\n      <td>0.903069</td>\n      <td>0.682827</td>\n      <td>...</td>\n      <td>0.893108</td>\n      <td>0.604163</td>\n      <td>0.675502</td>\n      <td>0.811303</td>\n      <td>0.700085</td>\n      <td>0.871927</td>\n      <td>0.610167</td>\n      <td>0.736642</td>\n      <td>0.609190</td>\n      <td>0.587034</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>50</td>\n      <td>5000</td>\n      <td>0.640371</td>\n      <td>False</td>\n      <td>0.806700</td>\n      <td>0.709277</td>\n      <td>0.806349</td>\n      <td>0.761074</td>\n      <td>0.906458</td>\n      <td>0.707124</td>\n      <td>...</td>\n      <td>0.897717</td>\n      <td>0.616255</td>\n      <td>0.675951</td>\n      <td>0.809635</td>\n      <td>0.714197</td>\n      <td>0.863989</td>\n      <td>0.612278</td>\n      <td>0.750632</td>\n      <td>0.638440</td>\n      <td>0.589307</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>50</td>\n      <td>10000</td>\n      <td>0.634603</td>\n      <td>True</td>\n      <td>0.803761</td>\n      <td>0.712509</td>\n      <td>0.804871</td>\n      <td>0.724833</td>\n      <td>0.908812</td>\n      <td>0.674460</td>\n      <td>...</td>\n      <td>0.882503</td>\n      <td>0.601166</td>\n      <td>0.675611</td>\n      <td>0.807482</td>\n      <td>0.693009</td>\n      <td>0.862675</td>\n      <td>0.600355</td>\n      <td>0.734228</td>\n      <td>0.632646</td>\n      <td>0.580198</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>50</td>\n      <td>10000</td>\n      <td>0.641547</td>\n      <td>False</td>\n      <td>0.815699</td>\n      <td>0.712450</td>\n      <td>0.809029</td>\n      <td>0.739397</td>\n      <td>0.909297</td>\n      <td>0.700649</td>\n      <td>...</td>\n      <td>0.892027</td>\n      <td>0.628997</td>\n      <td>0.693174</td>\n      <td>0.804747</td>\n      <td>0.715261</td>\n      <td>0.877706</td>\n      <td>0.614426</td>\n      <td>0.747058</td>\n      <td>0.631057</td>\n      <td>0.600866</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>50</td>\n      <td>20000</td>\n      <td>0.639218</td>\n      <td>True</td>\n      <td>0.822059</td>\n      <td>0.715044</td>\n      <td>0.806388</td>\n      <td>0.719979</td>\n      <td>0.904981</td>\n      <td>0.673323</td>\n      <td>...</td>\n      <td>0.889705</td>\n      <td>0.610741</td>\n      <td>0.688052</td>\n      <td>0.807494</td>\n      <td>0.705071</td>\n      <td>0.870050</td>\n      <td>0.611434</td>\n      <td>0.743066</td>\n      <td>0.625569</td>\n      <td>0.592557</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>50</td>\n      <td>20000</td>\n      <td>0.641626</td>\n      <td>False</td>\n      <td>0.815322</td>\n      <td>0.710804</td>\n      <td>0.812502</td>\n      <td>0.750218</td>\n      <td>0.907070</td>\n      <td>0.691361</td>\n      <td>...</td>\n      <td>0.890494</td>\n      <td>0.619732</td>\n      <td>0.679847</td>\n      <td>0.806042</td>\n      <td>0.701378</td>\n      <td>0.856203</td>\n      <td>0.627902</td>\n      <td>0.748398</td>\n      <td>0.639011</td>\n      <td>0.605466</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>50</td>\n      <td>50000</td>\n      <td>0.633337</td>\n      <td>True</td>\n      <td>0.805759</td>\n      <td>0.712286</td>\n      <td>0.797797</td>\n      <td>0.712642</td>\n      <td>0.908266</td>\n      <td>0.705539</td>\n      <td>...</td>\n      <td>0.888706</td>\n      <td>0.605471</td>\n      <td>0.670208</td>\n      <td>0.804292</td>\n      <td>0.698969</td>\n      <td>0.854916</td>\n      <td>0.605129</td>\n      <td>0.737237</td>\n      <td>0.631194</td>\n      <td>0.583597</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>50</td>\n      <td>50000</td>\n      <td>0.637281</td>\n      <td>False</td>\n      <td>0.814321</td>\n      <td>0.709132</td>\n      <td>0.804625</td>\n      <td>0.732708</td>\n      <td>0.907169</td>\n      <td>0.701169</td>\n      <td>...</td>\n      <td>0.890817</td>\n      <td>0.612637</td>\n      <td>0.673826</td>\n      <td>0.810618</td>\n      <td>0.695417</td>\n      <td>0.860037</td>\n      <td>0.616025</td>\n      <td>0.740748</td>\n      <td>0.628008</td>\n      <td>0.592566</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>100</td>\n      <td>5000</td>\n      <td>0.644396</td>\n      <td>True</td>\n      <td>0.808916</td>\n      <td>0.713430</td>\n      <td>0.797068</td>\n      <td>0.732729</td>\n      <td>0.914352</td>\n      <td>0.707088</td>\n      <td>...</td>\n      <td>0.893411</td>\n      <td>0.605195</td>\n      <td>0.678847</td>\n      <td>0.819875</td>\n      <td>0.736066</td>\n      <td>0.887044</td>\n      <td>0.595163</td>\n      <td>0.723455</td>\n      <td>0.626420</td>\n      <td>0.588797</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>100</td>\n      <td>5000</td>\n      <td>0.640910</td>\n      <td>False</td>\n      <td>0.819945</td>\n      <td>0.720473</td>\n      <td>0.800235</td>\n      <td>0.716999</td>\n      <td>0.916072</td>\n      <td>0.705030</td>\n      <td>...</td>\n      <td>0.892426</td>\n      <td>0.611935</td>\n      <td>0.676957</td>\n      <td>0.799733</td>\n      <td>0.732827</td>\n      <td>0.851822</td>\n      <td>0.600204</td>\n      <td>0.736105</td>\n      <td>0.637570</td>\n      <td>0.592498</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>100</td>\n      <td>10000</td>\n      <td>0.635769</td>\n      <td>True</td>\n      <td>0.807900</td>\n      <td>0.705091</td>\n      <td>0.794537</td>\n      <td>0.724268</td>\n      <td>0.910879</td>\n      <td>0.692033</td>\n      <td>...</td>\n      <td>0.892528</td>\n      <td>0.600661</td>\n      <td>0.649540</td>\n      <td>0.782874</td>\n      <td>0.715703</td>\n      <td>0.867070</td>\n      <td>0.578949</td>\n      <td>0.723180</td>\n      <td>0.613185</td>\n      <td>0.588468</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>100</td>\n      <td>10000</td>\n      <td>0.640626</td>\n      <td>False</td>\n      <td>0.816805</td>\n      <td>0.710990</td>\n      <td>0.798593</td>\n      <td>0.732208</td>\n      <td>0.916722</td>\n      <td>0.696721</td>\n      <td>...</td>\n      <td>0.895107</td>\n      <td>0.610946</td>\n      <td>0.683818</td>\n      <td>0.785289</td>\n      <td>0.722327</td>\n      <td>0.866033</td>\n      <td>0.585477</td>\n      <td>0.725230</td>\n      <td>0.639375</td>\n      <td>0.600434</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>100</td>\n      <td>20000</td>\n      <td>0.634468</td>\n      <td>True</td>\n      <td>0.811229</td>\n      <td>0.712020</td>\n      <td>0.786936</td>\n      <td>0.723225</td>\n      <td>0.916330</td>\n      <td>0.686595</td>\n      <td>...</td>\n      <td>0.898420</td>\n      <td>0.584977</td>\n      <td>0.660957</td>\n      <td>0.810016</td>\n      <td>0.736972</td>\n      <td>0.841345</td>\n      <td>0.574102</td>\n      <td>0.714517</td>\n      <td>0.613484</td>\n      <td>0.586604</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>100</td>\n      <td>20000</td>\n      <td>0.639311</td>\n      <td>False</td>\n      <td>0.812548</td>\n      <td>0.716528</td>\n      <td>0.799641</td>\n      <td>0.715623</td>\n      <td>0.918153</td>\n      <td>0.688575</td>\n      <td>...</td>\n      <td>0.904363</td>\n      <td>0.610117</td>\n      <td>0.665316</td>\n      <td>0.803013</td>\n      <td>0.733927</td>\n      <td>0.864956</td>\n      <td>0.584305</td>\n      <td>0.731450</td>\n      <td>0.629986</td>\n      <td>0.591890</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>100</td>\n      <td>50000</td>\n      <td>0.635049</td>\n      <td>True</td>\n      <td>0.817061</td>\n      <td>0.713137</td>\n      <td>0.789706</td>\n      <td>0.717690</td>\n      <td>0.917147</td>\n      <td>0.686247</td>\n      <td>...</td>\n      <td>0.893282</td>\n      <td>0.607169</td>\n      <td>0.650784</td>\n      <td>0.809766</td>\n      <td>0.729495</td>\n      <td>0.841422</td>\n      <td>0.572425</td>\n      <td>0.717922</td>\n      <td>0.622149</td>\n      <td>0.593278</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>100</td>\n      <td>50000</td>\n      <td>0.636830</td>\n      <td>False</td>\n      <td>0.816016</td>\n      <td>0.710926</td>\n      <td>0.794728</td>\n      <td>0.715158</td>\n      <td>0.916056</td>\n      <td>0.677180</td>\n      <td>...</td>\n      <td>0.896296</td>\n      <td>0.605041</td>\n      <td>0.660071</td>\n      <td>0.806912</td>\n      <td>0.717238</td>\n      <td>0.860621</td>\n      <td>0.573519</td>\n      <td>0.721782</td>\n      <td>0.623387</td>\n      <td>0.601289</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>150</td>\n      <td>5000</td>\n      <td>0.645653</td>\n      <td>True</td>\n      <td>0.816402</td>\n      <td>0.717647</td>\n      <td>0.786124</td>\n      <td>0.751528</td>\n      <td>0.920464</td>\n      <td>0.691433</td>\n      <td>...</td>\n      <td>0.907813</td>\n      <td>0.602803</td>\n      <td>0.662747</td>\n      <td>0.817021</td>\n      <td>0.760172</td>\n      <td>0.841607</td>\n      <td>0.562677</td>\n      <td>0.713477</td>\n      <td>0.633866</td>\n      <td>0.599806</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>150</td>\n      <td>5000</td>\n      <td>0.647493</td>\n      <td>False</td>\n      <td>0.818825</td>\n      <td>0.724397</td>\n      <td>0.792945</td>\n      <td>0.728354</td>\n      <td>0.922355</td>\n      <td>0.711016</td>\n      <td>...</td>\n      <td>0.900312</td>\n      <td>0.606382</td>\n      <td>0.664979</td>\n      <td>0.800911</td>\n      <td>0.746369</td>\n      <td>0.848282</td>\n      <td>0.573279</td>\n      <td>0.720777</td>\n      <td>0.629120</td>\n      <td>0.622647</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>150</td>\n      <td>10000</td>\n      <td>0.639873</td>\n      <td>True</td>\n      <td>0.819341</td>\n      <td>0.731598</td>\n      <td>0.767386</td>\n      <td>0.737361</td>\n      <td>0.919761</td>\n      <td>0.687689</td>\n      <td>...</td>\n      <td>0.904447</td>\n      <td>0.553239</td>\n      <td>0.641458</td>\n      <td>0.817629</td>\n      <td>0.756424</td>\n      <td>0.869308</td>\n      <td>0.537045</td>\n      <td>0.684667</td>\n      <td>0.626968</td>\n      <td>0.601779</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>150</td>\n      <td>10000</td>\n      <td>0.642713</td>\n      <td>False</td>\n      <td>0.823097</td>\n      <td>0.721176</td>\n      <td>0.782969</td>\n      <td>0.745190</td>\n      <td>0.920688</td>\n      <td>0.696585</td>\n      <td>...</td>\n      <td>0.900653</td>\n      <td>0.609236</td>\n      <td>0.675393</td>\n      <td>0.808523</td>\n      <td>0.746993</td>\n      <td>0.859016</td>\n      <td>0.536190</td>\n      <td>0.704308</td>\n      <td>0.635936</td>\n      <td>0.613312</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>150</td>\n      <td>20000</td>\n      <td>0.641065</td>\n      <td>True</td>\n      <td>0.816463</td>\n      <td>0.729651</td>\n      <td>0.784465</td>\n      <td>0.731661</td>\n      <td>0.919502</td>\n      <td>0.689549</td>\n      <td>...</td>\n      <td>0.900297</td>\n      <td>0.587287</td>\n      <td>0.636929</td>\n      <td>0.788125</td>\n      <td>0.750916</td>\n      <td>0.874065</td>\n      <td>0.552410</td>\n      <td>0.703264</td>\n      <td>0.619571</td>\n      <td>0.593335</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>150</td>\n      <td>20000</td>\n      <td>0.644950</td>\n      <td>False</td>\n      <td>0.821964</td>\n      <td>0.729761</td>\n      <td>0.786297</td>\n      <td>0.741466</td>\n      <td>0.923426</td>\n      <td>0.695033</td>\n      <td>...</td>\n      <td>0.903501</td>\n      <td>0.587224</td>\n      <td>0.674264</td>\n      <td>0.815600</td>\n      <td>0.752969</td>\n      <td>0.877371</td>\n      <td>0.543986</td>\n      <td>0.711297</td>\n      <td>0.639138</td>\n      <td>0.605151</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>150</td>\n      <td>50000</td>\n      <td>0.638521</td>\n      <td>True</td>\n      <td>0.810886</td>\n      <td>0.734582</td>\n      <td>0.785257</td>\n      <td>0.730699</td>\n      <td>0.921836</td>\n      <td>0.694081</td>\n      <td>...</td>\n      <td>0.900994</td>\n      <td>0.601865</td>\n      <td>0.641191</td>\n      <td>0.810609</td>\n      <td>0.743593</td>\n      <td>0.839616</td>\n      <td>0.548682</td>\n      <td>0.705832</td>\n      <td>0.637768</td>\n      <td>0.594922</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>150</td>\n      <td>50000</td>\n      <td>0.636158</td>\n      <td>False</td>\n      <td>0.826864</td>\n      <td>0.718977</td>\n      <td>0.784547</td>\n      <td>0.719794</td>\n      <td>0.915681</td>\n      <td>0.696849</td>\n      <td>...</td>\n      <td>0.901996</td>\n      <td>0.591715</td>\n      <td>0.646083</td>\n      <td>0.804160</td>\n      <td>0.748201</td>\n      <td>0.842878</td>\n      <td>0.546464</td>\n      <td>0.699850</td>\n      <td>0.635501</td>\n      <td>0.605781</td>\n    </tr>\n  </tbody>\n</table>\n<p>32 rows × 42 columns</p>\n</div>",
      "text/plain": "    clusters  samples     anmrr  undersampling  airplane  baseball_field  \\\n0         25     5000  0.644832           True  0.791870        0.713724   \n1         25     5000  0.646735          False  0.804999        0.699511   \n2         25    10000  0.647640           True  0.807403        0.705663   \n3         25    10000  0.647344          False  0.803732        0.706661   \n4         25    20000  0.646314           True  0.799734        0.707380   \n5         25    20000  0.645569          False  0.805595        0.700851   \n6         25    50000  0.648583           True  0.804629        0.700860   \n7         25    50000  0.651079          False  0.810678        0.701116   \n8         50     5000  0.637655           True  0.801461        0.711654   \n9         50     5000  0.640371          False  0.806700        0.709277   \n10        50    10000  0.634603           True  0.803761        0.712509   \n11        50    10000  0.641547          False  0.815699        0.712450   \n12        50    20000  0.639218           True  0.822059        0.715044   \n13        50    20000  0.641626          False  0.815322        0.710804   \n14        50    50000  0.633337           True  0.805759        0.712286   \n15        50    50000  0.637281          False  0.814321        0.709132   \n16       100     5000  0.644396           True  0.808916        0.713430   \n17       100     5000  0.640910          False  0.819945        0.720473   \n18       100    10000  0.635769           True  0.807900        0.705091   \n19       100    10000  0.640626          False  0.816805        0.710990   \n20       100    20000  0.634468           True  0.811229        0.712020   \n21       100    20000  0.639311          False  0.812548        0.716528   \n22       100    50000  0.635049           True  0.817061        0.713137   \n23       100    50000  0.636830          False  0.816016        0.710926   \n24       150     5000  0.645653           True  0.816402        0.717647   \n25       150     5000  0.647493          False  0.818825        0.724397   \n26       150    10000  0.639873           True  0.819341        0.731598   \n27       150    10000  0.642713          False  0.823097        0.721176   \n28       150    20000  0.641065           True  0.816463        0.729651   \n29       150    20000  0.644950          False  0.821964        0.729761   \n30       150    50000  0.638521           True  0.810886        0.734582   \n31       150    50000  0.636158          False  0.826864        0.718977   \n\n    basketball_court     beach    bridge  cemetery  ...    runway  \\\n0           0.817263  0.763676  0.898288  0.701439  ...  0.888172   \n1           0.813308  0.781790  0.900840  0.709100  ...  0.894411   \n2           0.816795  0.772648  0.897284  0.692943  ...  0.891773   \n3           0.819695  0.786367  0.896956  0.700060  ...  0.887271   \n4           0.815179  0.774624  0.897977  0.699360  ...  0.885199   \n5           0.817944  0.784607  0.900008  0.708243  ...  0.890112   \n6           0.815215  0.786506  0.901078  0.702336  ...  0.891594   \n7           0.814006  0.780173  0.899064  0.709085  ...  0.894761   \n8           0.799366  0.721935  0.903069  0.682827  ...  0.893108   \n9           0.806349  0.761074  0.906458  0.707124  ...  0.897717   \n10          0.804871  0.724833  0.908812  0.674460  ...  0.882503   \n11          0.809029  0.739397  0.909297  0.700649  ...  0.892027   \n12          0.806388  0.719979  0.904981  0.673323  ...  0.889705   \n13          0.812502  0.750218  0.907070  0.691361  ...  0.890494   \n14          0.797797  0.712642  0.908266  0.705539  ...  0.888706   \n15          0.804625  0.732708  0.907169  0.701169  ...  0.890817   \n16          0.797068  0.732729  0.914352  0.707088  ...  0.893411   \n17          0.800235  0.716999  0.916072  0.705030  ...  0.892426   \n18          0.794537  0.724268  0.910879  0.692033  ...  0.892528   \n19          0.798593  0.732208  0.916722  0.696721  ...  0.895107   \n20          0.786936  0.723225  0.916330  0.686595  ...  0.898420   \n21          0.799641  0.715623  0.918153  0.688575  ...  0.904363   \n22          0.789706  0.717690  0.917147  0.686247  ...  0.893282   \n23          0.794728  0.715158  0.916056  0.677180  ...  0.896296   \n24          0.786124  0.751528  0.920464  0.691433  ...  0.907813   \n25          0.792945  0.728354  0.922355  0.711016  ...  0.900312   \n26          0.767386  0.737361  0.919761  0.687689  ...  0.904447   \n27          0.782969  0.745190  0.920688  0.696585  ...  0.900653   \n28          0.784465  0.731661  0.919502  0.689549  ...  0.900297   \n29          0.786297  0.741466  0.923426  0.695033  ...  0.903501   \n30          0.785257  0.730699  0.921836  0.694081  ...  0.900994   \n31          0.784547  0.719794  0.915681  0.696849  ...  0.901996   \n\n    runway_marking  shipping_yard  solar_panel  sparse_residential  \\\n0         0.638481       0.706393     0.804582            0.680476   \n1         0.637496       0.720900     0.800527            0.684579   \n2         0.634719       0.716084     0.800317            0.686905   \n3         0.574070       0.725146     0.797050            0.695257   \n4         0.625499       0.711819     0.810539            0.681311   \n5         0.596740       0.717653     0.807429            0.692721   \n6         0.636579       0.709716     0.803821            0.682903   \n7         0.637647       0.722124     0.803145            0.692819   \n8         0.604163       0.675502     0.811303            0.700085   \n9         0.616255       0.675951     0.809635            0.714197   \n10        0.601166       0.675611     0.807482            0.693009   \n11        0.628997       0.693174     0.804747            0.715261   \n12        0.610741       0.688052     0.807494            0.705071   \n13        0.619732       0.679847     0.806042            0.701378   \n14        0.605471       0.670208     0.804292            0.698969   \n15        0.612637       0.673826     0.810618            0.695417   \n16        0.605195       0.678847     0.819875            0.736066   \n17        0.611935       0.676957     0.799733            0.732827   \n18        0.600661       0.649540     0.782874            0.715703   \n19        0.610946       0.683818     0.785289            0.722327   \n20        0.584977       0.660957     0.810016            0.736972   \n21        0.610117       0.665316     0.803013            0.733927   \n22        0.607169       0.650784     0.809766            0.729495   \n23        0.605041       0.660071     0.806912            0.717238   \n24        0.602803       0.662747     0.817021            0.760172   \n25        0.606382       0.664979     0.800911            0.746369   \n26        0.553239       0.641458     0.817629            0.756424   \n27        0.609236       0.675393     0.808523            0.746993   \n28        0.587287       0.636929     0.788125            0.750916   \n29        0.587224       0.674264     0.815600            0.752969   \n30        0.601865       0.641191     0.810609            0.743593   \n31        0.591715       0.646083     0.804160            0.748201   \n\n    storage_tank  swimming_pool  tennis_court  transformer_station  \\\n0       0.874000       0.647231      0.759410             0.629754   \n1       0.873482       0.646908      0.764294             0.625601   \n2       0.873231       0.635611      0.755900             0.616440   \n3       0.874446       0.647427      0.770502             0.639442   \n4       0.876578       0.639546      0.752009             0.618774   \n5       0.868053       0.646169      0.765396             0.630462   \n6       0.875803       0.640217      0.763071             0.617895   \n7       0.874163       0.657273      0.759544             0.642925   \n8       0.871927       0.610167      0.736642             0.609190   \n9       0.863989       0.612278      0.750632             0.638440   \n10      0.862675       0.600355      0.734228             0.632646   \n11      0.877706       0.614426      0.747058             0.631057   \n12      0.870050       0.611434      0.743066             0.625569   \n13      0.856203       0.627902      0.748398             0.639011   \n14      0.854916       0.605129      0.737237             0.631194   \n15      0.860037       0.616025      0.740748             0.628008   \n16      0.887044       0.595163      0.723455             0.626420   \n17      0.851822       0.600204      0.736105             0.637570   \n18      0.867070       0.578949      0.723180             0.613185   \n19      0.866033       0.585477      0.725230             0.639375   \n20      0.841345       0.574102      0.714517             0.613484   \n21      0.864956       0.584305      0.731450             0.629986   \n22      0.841422       0.572425      0.717922             0.622149   \n23      0.860621       0.573519      0.721782             0.623387   \n24      0.841607       0.562677      0.713477             0.633866   \n25      0.848282       0.573279      0.720777             0.629120   \n26      0.869308       0.537045      0.684667             0.626968   \n27      0.859016       0.536190      0.704308             0.635936   \n28      0.874065       0.552410      0.703264             0.619571   \n29      0.877371       0.543986      0.711297             0.639138   \n30      0.839616       0.548682      0.705832             0.637768   \n31      0.842878       0.546464      0.699850             0.635501   \n\n    wastewater_treatment_plant  \n0                     0.585639  \n1                     0.584447  \n2                     0.561037  \n3                     0.586556  \n4                     0.565003  \n5                     0.583237  \n6                     0.578936  \n7                     0.571599  \n8                     0.587034  \n9                     0.589307  \n10                    0.580198  \n11                    0.600866  \n12                    0.592557  \n13                    0.605466  \n14                    0.583597  \n15                    0.592566  \n16                    0.588797  \n17                    0.592498  \n18                    0.588468  \n19                    0.600434  \n20                    0.586604  \n21                    0.591890  \n22                    0.593278  \n23                    0.601289  \n24                    0.599806  \n25                    0.622647  \n26                    0.601779  \n27                    0.613312  \n28                    0.593335  \n29                    0.605151  \n30                    0.594922  \n31                    0.605781  \n\n[32 rows x 42 columns]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}