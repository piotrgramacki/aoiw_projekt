{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Conv2d, MaxPool2d, Flatten\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "from src.data.ucmerced_dataset import UcMercedDataset\n",
    "from src.data.orto_dataset import OrtoDataset\n",
    "from src.settings import DATA_DIRECTORY\n",
    "from src.settings import TRAIN_DATA_DIRECTORY, TEST_DATA_DIRECTORY\n",
    "from src.evaluation import evaluate_anmrr, evaluate_loss\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def soft_pn(a, p, n):\n",
    "    def dist(x, y):\n",
    "        return torch.linalg.norm((x - y))\n",
    "    \n",
    "    dist_p = dist(a, p)\n",
    "    dist_n1 = dist(a, n)\n",
    "    dist_n2 = dist(p, n)\n",
    "\n",
    "    min_n_dist = torch.minimum(dist_n1, dist_n2)\n",
    "\n",
    "    pos_exp = dist_p.exp()\n",
    "    min_n_exp = min_n_dist.exp()\n",
    "\n",
    "    l = (pos_exp / (min_n_exp + pos_exp)).pow(2) + (min_n_exp / (min_n_exp + pos_exp) - 1).pow(2)\n",
    "    return l.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "train_dataset = UcMercedDataset(TRAIN_DATA_DIRECTORY, image_size, train=True)\n",
    "test_dataset = UcMercedDataset(TEST_DATA_DIRECTORY, image_size, train=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=80, shuffle=True, num_workers=10)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=100, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_training_model_layers(model, training: bool, up_to_index: int):\n",
    "    i = 0\n",
    "    for child in model.children():\n",
    "        if i > up_to_index:\n",
    "            break\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = training\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\r\n",
    "from tqdm import tqdm, trange\r\n",
    "from torch.nn import Sequential, Linear, ReLU, Conv2d, MaxPool2d, Flatten, LocalResponseNorm, BatchNorm2d, LeakyReLU, Tanh\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "from torch.optim import lr_scheduler\r\n",
    "\r\n",
    "act = LeakyReLU()\r\n",
    "\r\n",
    "model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\r\n",
    "\r\n",
    "model.fc = torch.nn.Linear(512, 50, bias=True)\r\n",
    "set_training_model_layers(model, False, 8)\r\n",
    "\r\n",
    "model = model.cuda()\r\n",
    "\r\n",
    "optim = torch.optim.Adam(model.parameters(), weight_decay=1e-5)\r\n",
    "criterion = torch.nn.TripletMarginLoss()\r\n",
    "\r\n",
    "def evaluate_model(model, train: DataLoader, test: DataLoader, criterion):\r\n",
    "    model.train(False)\r\n",
    "    with torch.no_grad():\r\n",
    "        test_loss = evaluate_loss(model, test, criterion)\r\n",
    "\r\n",
    "        train_anmrr = evaluate_anmrr(model, train_dataloader, euclidean_distances)\r\n",
    "        test_anmrr = evaluate_anmrr(model, test_dataloader, euclidean_distances)\r\n",
    "\r\n",
    "    model.train(True)\r\n",
    "\r\n",
    "    return test_loss, train_anmrr, test_anmrr\r\n",
    "\r\n",
    "\r\n",
    "writer = SummaryWriter()\r\n",
    "t = trange(25)\r\n",
    "for epoch in t:\r\n",
    "    loss_sum = 0.0\r\n",
    "    for i_batch, sample_batched in enumerate(train_dataloader):\r\n",
    "        optim.zero_grad()\r\n",
    "        \r\n",
    "        anchors = sample_batched['a'].cuda()\r\n",
    "        positives = sample_batched['p'].cuda()\r\n",
    "        negatives = sample_batched['n'].cuda()\r\n",
    "        a = model(anchors)\r\n",
    "        p = model(positives)\r\n",
    "        n = model(negatives)\r\n",
    "        loss = criterion(a, p, n)\r\n",
    "        loss.backward()\r\n",
    "        loss_sum += float(loss)\r\n",
    "        optim.step()\r\n",
    "        t.set_description(f\"Batch: {i_batch}\")\r\n",
    "    del a\r\n",
    "    del p\r\n",
    "    del n\r\n",
    "    del loss\r\n",
    "    \r\n",
    "    train_loss = loss_sum / len(train_dataloader)\r\n",
    "\r\n",
    "    test_loss, train_anmmr, test_anmrr = evaluate_model(model, train_dataloader, test_dataloader, criterion)\r\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\r\n",
    "    writer.add_scalar('Loss/test', test_loss, epoch)\r\n",
    "    writer.add_scalar('ANMRR/train', train_anmmr, epoch)\r\n",
    "    writer.add_scalar('ANMRR/test', test_anmrr, epoch)\r\n",
    "    t.set_description(f\"Epoch: {epoch}, Train loss: {train_loss}\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "embeddings = []\n",
    "classes = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "        anchors = sample_batched['a'].cuda()\n",
    "        y = sample_batched['a_y']\n",
    "        classes.append(y.cpu().numpy())\n",
    "        anchor_paths = sample_batched['path']\n",
    "        paths.extend(anchor_paths)\n",
    "        a = model(anchors).cpu().numpy()\n",
    "        embeddings.append(a)\n",
    "\n",
    "    embeddings = np.concatenate(embeddings)\n",
    "    classes = np.concatenate(classes)\n",
    "\n",
    "import pickle as pkl\n",
    "with open(\"merced_embeddings.pkl.gz\", \"wb\") as f:\n",
    "    pkl.dump((paths, embeddings, classes), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "tsne_embeddings = TSNE(n_components=2).fit_transform(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "def visualize_tsne_embeddings(embeddings: np.array, image_paths):\n",
    "\n",
    "    def get_image(path):\n",
    "        img = Image.open(path)\n",
    "        # img.resize((10,10))\n",
    "        a = np.asarray(img)\n",
    "        return OffsetImage(a, zoom=0.15)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    ax.scatter(embeddings[:, 0], embeddings[:, 1]) \n",
    "    for image_path, (x, y) in zip(image_paths, tsne_embeddings):\n",
    "        ab = AnnotationBbox(get_image(image_path), (x, y), frameon=False)\n",
    "        ax.add_artist(ab)\n",
    "    fig.savefig(\"merced_embeddings.png\", dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "\n",
    "visualize_tsne_embeddings(tsne_embeddings, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "distances = euclidean_distances(embeddings)\n",
    "if(len(classes.shape) < 2):\n",
    "    classes = classes[:, None]\n",
    "\n",
    "paths = np.array(paths).squeeze()\n",
    "rankings = np.argsort(distances, axis=1)\n",
    "selected_images = paths[rankings]\n",
    "\n",
    "cols = 6\n",
    "rows = 6\n",
    "\n",
    "for label, name in test_dataset.label_name_mapping.items():\n",
    "    \n",
    "    indices_with_class = np.argwhere(classes == label)[:, 0].squeeze()\n",
    "    example_query_index = np.random.choice(indices_with_class)\n",
    "\n",
    "    query_image_path = paths[example_query_index]\n",
    "    example_query = selected_images[example_query_index, :].squeeze()\n",
    "\n",
    "    query_image = io.imread(query_image_path)\n",
    "    \n",
    "    fig=plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(query_image)\n",
    "    query_image_name = os.path.split(query_image_path)[1]\n",
    "    plt.title(f\"Query: {query_image_name}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    for i in range (cols * rows):\n",
    "        path = example_query[i]\n",
    "        image = io.imread(path)\n",
    "        fig.add_subplot(rows, cols, i+1)\n",
    "        plt.title(os.path.split(path)[1])\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.imshow(image)\n",
    "    fig.suptitle(f\"Response to query: {query_image_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(False)\n",
    "with torch.no_grad():\n",
    "    test_anmrr, class_anmrr = evaluate_anmrr(model, test_dataloader, euclidean_distances, class_mean=True)\n",
    "model.train(True)\n",
    "anmrr_with_labels = [(train_dataset.label_name_mapping[c], value) for c, value in class_anmrr]\n",
    "anmrr_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\r\n",
    "names, values = list(zip(*anmrr_with_labels))\r\n",
    "fig = px.bar(x=names, y=values)\r\n",
    "fig.show(renderer='browser')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}