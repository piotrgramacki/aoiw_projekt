{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from tqdm import trange, tqdm\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from src.data.orto_dataset import OrtoDataset\r\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\r\n",
    "dataset = OrtoDataset(\"..\\\\..\\\\datasets\\\\orto_triplet_dataset\", image_size, train=True)\r\n",
    "train_dataloader = DataLoader(dataset, batch_size=150, shuffle=True, num_workers=10, prefetch_factor=4)\r\n",
    "\r\n",
    "\r\n",
    "test_dataset = OrtoDataset(\"..\\\\..\\\\datasets\\\\orto_triplet_dataset\", image_size, train=False)\r\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=100, num_workers=10, prefetch_factor=4)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_training_model_layers(model, training: bool, up_to_index: int):\r\n",
    "    i = 0\r\n",
    "    for child in model.children():\r\n",
    "        if i > up_to_index:\r\n",
    "            break\r\n",
    "        for param in child.parameters():\r\n",
    "            param.requires_grad = training\r\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_state(path):\r\n",
    "    model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\r\n",
    "    model.fc = torch.nn.Linear(512, 100, bias=True)\r\n",
    "    set_training_model_layers(model, False, 8)\r\n",
    "    model = model.cuda()\r\n",
    "    optim = torch.optim.Adam(model.parameters(), weight_decay=1e-5)\r\n",
    "\r\n",
    "    checkpoint = torch.load(path)\r\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\r\n",
    "    optim.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
    "\r\n",
    "    return model, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\r\n",
    "\r\n",
    "# model.fc = torch.nn.Linear(512, 100, bias=True)\r\n",
    "# set_training_model_layers(model, False, 8)\r\n",
    "# model = model.cuda()\r\n",
    "# optim = torch.optim.Adam(model.parameters(), weight_decay=1e-5)\r\n",
    "model, optim = load_training_state(\"300_checkpoint.pt\")\r\n",
    "criterion = torch.nn.TripletMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_training_model_layers(model, True, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "iters = 302\r\n",
    "writer = SummaryWriter()\r\n",
    "t = trange(iters)\r\n",
    "for epoch in t:\r\n",
    "    loss_sum = 0.0\r\n",
    "    for i_batch, sample_batched in enumerate(train_dataloader):\r\n",
    "        optim.zero_grad()\r\n",
    "        \r\n",
    "        anchors = sample_batched['a'].cuda()\r\n",
    "        positives = sample_batched['p'].cuda()\r\n",
    "        negatives = sample_batched['n'].cuda()\r\n",
    "        a = model(anchors)\r\n",
    "        p = model(positives)\r\n",
    "        n = model(negatives)\r\n",
    "        loss = criterion(a, p, n)\r\n",
    "        loss.backward()\r\n",
    "        loss_sum += float(loss)\r\n",
    "        optim.step()\r\n",
    "        t.set_description(f\"Batch: {i_batch}\")\r\n",
    "    del a\r\n",
    "    del p\r\n",
    "    del n\r\n",
    "    del loss\r\n",
    "    \r\n",
    "    train_loss = loss_sum / len(train_dataloader)\r\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\r\n",
    "    t.set_description(f\"Epoch: {epoch}, Train loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\r\n",
    "embeddings = []\r\n",
    "\r\n",
    "with torch.no_grad():\r\n",
    "    for i_batch, sample_batched in tqdm(enumerate(test_dataloader)):\r\n",
    "        anchors = sample_batched['a'].cuda()\r\n",
    "        anchor_paths = sample_batched['path']\r\n",
    "        paths.extend(anchor_paths)\r\n",
    "        a = model(anchors).cpu().numpy()\r\n",
    "        embeddings.append(a)\r\n",
    "\r\n",
    "    embeddings = np.concatenate(embeddings)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\r\n",
    "with open(f\"embeddings_{iters}.pkl.gz\", \"wb\") as f:\r\n",
    "    pkl.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# tsne_embeddings = TSNE(n_components=2, verbose=100, n_jobs=15).fit_transform(embeddings)\r\n",
    "tsne_embeddings = PCA(n_components=2).fit_transform(embeddings)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import pickle as pkl\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.manifold import TSNE\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "with open(f\"embeddings_{302}.pkl.gz\", \"rb\") as f:\r\n",
    "    embeddings = pkl.load(f)\r\n",
    "# tsne_embeddings = PCA(n_components=2).fit_transform(embeddings)\r\n",
    "tsne_embeddings = TSNE(n_components=2, verbose=10, n_jobs=15).fit_transform(embeddings)\r\n",
    "with open(f\"tsne-embeddings_{iters}.pkl.gz\", \"wb\") as f:\r\n",
    "    pkl.dump(tsne_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\r\n",
    "            'epoch': 300,\r\n",
    "            'model_state_dict': model.state_dict(),\r\n",
    "            'optimizer_state_dict': optim.state_dict(),\r\n",
    "            }, \"300_checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [os.path.join(\"..\\\\..\\\\datasets\\\\orto_triplet_dataset\\\\anchor\",f) for f in os.listdir(\"..\\\\..\\\\datasets\\\\orto_triplet_dataset\\\\anchor\")]\r\n",
    "size = 5000\r\n",
    "random_selections = np.random.choice(np.arange(len(paths)), size=size, replace=False)\r\n",
    "\r\n",
    "selected_paths = np.array(paths)[random_selections].tolist()\r\n",
    "selected_embeddings = tsne_embeddings[random_selections, :]\r\n",
    "\r\n",
    "from PIL import Image\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from tqdm import tqdm\r\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\r\n",
    "\r\n",
    "\r\n",
    "def visualize_embeddings(embeddings: np.array, image_paths, name: str):\r\n",
    "\r\n",
    "    def get_image(path):\r\n",
    "        img = Image.open(path)\r\n",
    "        a = np.asarray(img)\r\n",
    "        return OffsetImage(a, zoom=0.08)\r\n",
    "\r\n",
    "\r\n",
    "    fig, ax = plt.subplots(figsize=(30,30))\r\n",
    "    ax.scatter(embeddings[:, 0], embeddings[:, 1]) \r\n",
    "    for image_path, (x, y) in tqdm(zip(image_paths, embeddings)):\r\n",
    "        ab = AnnotationBbox(get_image(image_path), (x, y), frameon=False)\r\n",
    "        ax.add_artist(ab)\r\n",
    "    fig.savefig(name, dpi=300)\r\n",
    "    print(\"saved\")\r\n",
    "    plt.close()\r\n",
    "\r\n",
    "    return 0\r\n",
    "\r\n",
    "visualize_embeddings(selected_embeddings, selected_paths, f\"tsne_{iters}.png\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\r\n",
    "with open(f\"embeddings_{iters}.pkl.gz\", \"rb\") as f:\r\n",
    "    embeddings = pkl.load(f)\r\n",
    "umap = UMAP().fit_transform(embeddings)\r\n",
    "paths = [os.path.join(\"..\\\\..\\\\datasets\\\\orto_triplet_dataset\\\\anchor\",f) for f in os.listdir(\"..\\\\..\\\\datasets\\\\orto_triplet_dataset\\\\anchor\")]\r\n",
    "size = 5000\r\n",
    "# random_selections = np.random.choice(np.arange(len(paths)), size=size, replace=False)\r\n",
    "\r\n",
    "# selected_paths = np.array(paths)[random_selections].tolist()\r\n",
    "selected_embeddings = umap[random_selections, :]\r\n",
    "visualize_embeddings(selected_embeddings, selected_paths, f\"umap_{iters}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"model_{iters}.pt\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\r\n",
    "\r\n",
    "distances = pairwise_distances(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "for i, ble in enumerate(paths):\r\n",
    "    if os.path.basename(ble) == \"orto2020split.40534.tif\":\r\n",
    "        found_i, found_path = i, ble\r\n",
    "        print(i, ble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(paths[found_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in distances[found_i, :].argsort()[:15]:\r\n",
    "    plt.imshow(Image.open(paths[i]))\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}