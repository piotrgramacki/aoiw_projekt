{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Conv2d, MaxPool2d, Flatten\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "from src.data.ucmerced_dataset import UcMercedDataset\n",
    "from src.settings import DATA_DIRECTORY\n",
    "from src.settings import TRAIN_DATA_DIRECTORY, TEST_DATA_DIRECTORY\n",
    "from src.evaluation import evaluate_anmrr, evaluate_loss\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def soft_pn(a, p, n):\n",
    "    def dist(x, y):\n",
    "        return (x - y).pow(2).sum(dim=1, keepdim=True)\n",
    "    \n",
    "    dist_p = dist(a, p)\n",
    "    dist_n1 = dist(a, n)\n",
    "    dist_n2 = dist(p, n)\n",
    "\n",
    "    min_n_dist = torch.minimum(dist_n1, dist_n2)\n",
    "\n",
    "    pos_exp = dist_p.exp()\n",
    "    min_n_exp = min_n_dist.exp()\n",
    "\n",
    "    l = (pos_exp / (min_n_exp + pos_exp)).pow(2) + (min_n_exp / (min_n_exp + pos_exp) -1).pow(2)\n",
    "    return l.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = UcMercedDataset(TRAIN_DATA_DIRECTORY)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=25,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = UcMercedDataset(TEST_DATA_DIRECTORY)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "from torch.nn import Sequential, Linear, ReLU, Conv2d, MaxPool2d, Flatten, LocalResponseNorm, BatchNorm2d, LeakyReLU\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "model = Sequential(\n",
    "    Conv2d(3, 32, (3, 3)),\n",
    "    BatchNorm2d(32),\n",
    "    LeakyReLU(),\n",
    "    MaxPool2d(2, 2),\n",
    "    LocalResponseNorm(2),\n",
    "    Conv2d(32, 32, (3, 3)),\n",
    "    BatchNorm2d(32),\n",
    "    LeakyReLU(),\n",
    "    MaxPool2d(2, 2),\n",
    "    LocalResponseNorm(2),\n",
    "    Conv2d(32, 64, (3, 3)),\n",
    "    BatchNorm2d(64),\n",
    "    LeakyReLU(),\n",
    "    MaxPool2d(2, 2),\n",
    "    LocalResponseNorm(2),\n",
    "    Flatten(),\n",
    "    Linear(57600, 100),\n",
    "    LeakyReLU(),\n",
    "    Linear(100, 100)\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.TripletMarginLoss()\n",
    "\n",
    "def evaluate_model(model, train: DataLoader, test: DataLoader, criterion):\n",
    "    model.train(False)\n",
    "    with torch.no_grad():\n",
    "        test_loss = evaluate_loss(model, test, criterion)\n",
    "\n",
    "        train_anmrr = evaluate_anmrr(model, train_dataloader, euclidean_distances)\n",
    "        test_anmrr = evaluate_anmrr(model, test_dataloader, euclidean_distances)\n",
    "\n",
    "    model.train(True)\n",
    "\n",
    "    return test_loss, train_anmrr, test_anmrr\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "t = trange(25)\n",
    "for epoch in t:\n",
    "    loss_sum = 0.0\n",
    "    for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "        optim.zero_grad()\n",
    "        anchors = sample_batched['a'].permute(0,3,1,2).float().cuda()\n",
    "        positives = sample_batched['p'].permute(0,3,1,2).float().cuda()\n",
    "        negatives = sample_batched['n'].permute(0,3,1,2).float().cuda()\n",
    "        a = model(anchors)\n",
    "        p = model(positives)\n",
    "        n = model(negatives)\n",
    "        loss = criterion(a, p, n)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optim.step()\n",
    "        t.set_description(f\"Batch: {i_batch}\")\n",
    "    \n",
    "    train_loss = loss_sum / len(train_dataloader)\n",
    "\n",
    "    test_loss, train_anmmr, test_anmrr = evaluate_model(model, train_dataloader, test_dataloader, criterion)\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "    writer.add_scalar('ANMRR/train', train_anmmr, epoch)\n",
    "    writer.add_scalar('ANMRR/test', test_anmrr, epoch)\n",
    "    t.set_description(f\"Epoch: {epoch}, Train loss: {train_loss}, Test loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "embeddings = []\n",
    "classes = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "        anchors = sample_batched['a'].permute(0, 3, 1, 2).float().cuda()\n",
    "        y = sample_batched['a_y']\n",
    "        classes.append(y.cpu().numpy())\n",
    "        anchor_paths = sample_batched['path']\n",
    "        paths.extend(anchor_paths)\n",
    "        a = model(anchors).cpu().numpy()\n",
    "        embeddings.append(a)\n",
    "\n",
    "    embeddings = np.concatenate(embeddings)\n",
    "    classes = np.concatenate(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "distances = euclidean_distances(embeddings)\n",
    "if(len(classes.shape) < 2):\n",
    "    classes = classes[:, None]\n",
    "\n",
    "paths = np.array(paths).squeeze()\n",
    "rankings = np.argsort(distances, axis=1)\n",
    "selected_images = paths[rankings]\n",
    "\n",
    "cols = 7\n",
    "rows = 7\n",
    "\n",
    "for label, name in test_dataset.label_name_mapping.items():\n",
    "    \n",
    "    indices_with_class = np.argwhere(classes == label)[:, 0].squeeze()\n",
    "    example_query_index = np.random.choice(indices_with_class)\n",
    "\n",
    "    query_image_path = paths[example_query_index]\n",
    "    example_query = selected_images[example_query_index, :].squeeze()\n",
    "\n",
    "    query_image = io.imread(query_image_path)\n",
    "    plt.imshow(query_image)\n",
    "    query_image_name = os.path.split(query_image_path)[1]\n",
    "    plt.title(f\"Query: {query_image_name}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    fig=plt.figure(figsize=(20, 20))\n",
    "    for i in range (cols * rows):\n",
    "        path = example_query[i]\n",
    "        image = io.imread(path)\n",
    "        fig.add_subplot(rows, cols, i+1)\n",
    "        plt.title(os.path.split(path)[1])\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.imshow(image)\n",
    "    fig.suptitle(f\"Response to query: {query_image_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}